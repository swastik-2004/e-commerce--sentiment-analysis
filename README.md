ğŸ§  Sentiment Analysis using DistilBERT

An end-to-end Sentiment Analysis System that classifies product reviews as Positive, Neutral, or Negative using DistilBERT from Hugging Face Transformers.

Built with:

ğŸ§© Hugging Face Transformers (for fine-tuning)

âš¡ PyTorch (for GPU acceleration)

ğŸŒ Streamlit (for real-time inference)

ğŸ“Š Matplotlib / Seaborn (for model evaluation)

ğŸš€ Features

âœ… Fine-tuned DistilBERT model on 500K+ cleaned Amazon product reviews
âœ… Interactive Streamlit web app for live sentiment prediction
âœ… Real-time confidence score visualization and feedback
âœ… Automatic prediction logging for analytics
âœ… Modular, production-ready code structure



ğŸ§  Model Overview

Base Model: distilbert-base-uncased
Fine-tuned on: Amazon product reviews (cleaned & labeled)
Classes:

0 â†’ Negative

1 â†’ Neutral

2 â†’ Positive

Final Evaluation:

Metric	Score
Accuracy	88.8%
Weighted F1	0.89
Dataset Size	~500,000 reviews
Model Size	~250MB
âš™ï¸ Installation
1ï¸âƒ£ Clone this repo
git clone https://github.com/<swastik-2004>/sentiment_analysis_project.git
cd sentiment_analysis_project

2ï¸âƒ£ Create and activate environment
conda create -n torch_gpu python=3.10
conda activate torch_gpu

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

ğŸ§© Usage
â–¶ï¸ Run the Streamlit app
streamlit run app.py


Open your browser at http://localhost:8501

Example input:

â€œThe product was very mediocre. It had flaws but still worked.â€

Example output:

Prediction: Neutral
Confidence: 96.9%

ğŸ“Š Dashboard (Optional Add-On)

A secondary Streamlit page that visualizes:

Sentiment distribution (Pie Chart)

Daily sentiment trends (Line Chart)

Recent predictions table

ğŸ“ Model Training Summary
Steps:

Cleaned dataset (Cleaned_Review, Sentiment)

Mapped labels â†’ 0, 1, 2

Tokenized with AutoTokenizer

Fine-tuned DistilBERT with Trainer

Saved final model to model/sentiment_bert/

Training Time: ~70s per epoch on RTX 3050
Loss: 0.43 after epoch 1
Eval Accuracy: ~88%

ğŸ§  Tech Stack
Area	Tools Used
Data Cleaning	Pandas, Regex
NLP Model	Hugging Face Transformers (DistilBERT)
Training Framework	PyTorch, Trainer API
Evaluation	Sklearn (F1, Accuracy, Confusion Matrix)
UI	Streamlit
Visualization	Matplotlib, Seaborn
Logging	CSV-based tracking for predictions
ğŸ§¾ Example Resume Line

Developed an end-to-end Sentiment Analysis Web App using DistilBERT, achieving 89% accuracy on 500K product reviews. Built a Streamlit UI with real-time confidence visualization and analytics logging.

ğŸŒ Future Improvements

âœ… Add FastAPI backend for scalable deployment

âœ… Integrate SQLAlchemy for user-based storage

âœ… Host model and app on Hugging Face Spaces or Streamlit Cloud

âœ… Add Admin Dashboard for trend monitoring

ğŸ§‘â€ğŸ’» Author

Swastik Dasgupta
ğŸ“ 3rd Year AIML, MSRIT
ğŸ’¼ Aspiring Machine Learning Engineer

â­ Acknowledgements

Hugging Face Transformers

Streamlit

PyTorch